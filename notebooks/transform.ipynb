{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff66992-070c-4ccb-9a71-e2a93ef9f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836d94f5-732c-45a2-a522-d5c85ecdee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = '/home/faisal/my_projects/de-reddit-reports/keys/de-reddit-reports-f9479aba34a3.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"../lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed621c5b-1189-4cbc-a22e-354417f546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/29 21:20:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccaaf31-b764-4142-8f60-3d03d88d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc416a6c-4a4c-46c8-a998-0466768b9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_post = spark.read.parquet('gs://reddit-terra-bucket/subreddit/dataengineering/post/2024/2/24/post.parquet')\n",
    "df_comment = spark.read.parquet('gs://reddit-terra-bucket/subreddit/dataengineering/comment/2024/2/24/comment.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2a697b-565c-4123-bb44-033cb0e88d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UDF for sentiment analysis to return sentiment score only\n",
    "def analyze_sentiment_score(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Register UDF\n",
    "sentiment_score_udf = udf(analyze_sentiment_score, T.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492b063d-d871-476e-823b-11852ec33d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_checksum_verification(posts_df, comments_df, joined_df):\n",
    "    try:\n",
    "        # Count the number of posts before the join\n",
    "        posts_count_before = posts_df.count()\n",
    "\n",
    "        # Count the number of comments before the join\n",
    "        comments_count_before = comments_df.count()\n",
    "\n",
    "        # Count the number of distinct non-null values in the 'post_id' column\n",
    "        posts_count_after = joined_df.filter(joined_df['post_id'].isNotNull()).select(F.col(\"post_id\")).distinct().count()\n",
    "\n",
    "        # Count the number of distinct non-null values in the 'comment_id' column\n",
    "        comments_count_after = joined_df.filter(joined_df['comment_id'].isNotNull()).select(F.col(\"comment_id\")).distinct().count()\n",
    "\n",
    "        # Perform count checksum verification\n",
    "        if posts_count_before == posts_count_after and comments_count_before == comments_count_after:\n",
    "            print(\"Count checksum verification passed.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during count checksum verification:\", str(e))\n",
    "        print(\"Count checksum verification failed.\\ncomments_count_before:{0}\\tcomments_count_after:{1} \\\n",
    "            \\nposts_count_before:{2}\\tposts_count_after:{3}\" \n",
    "                  .format(comments_count_before, comments_count_after,posts_count_before, posts_count_after)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473cd8af-38d4-43dd-9328-a683954af60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UDF to create column for sentiment score\n",
    "df_post_with_sentiment = df_post.withColumn(\"post_sentiment_score\", sentiment_score_udf(df_post[\"selftext\"]))\n",
    "\n",
    "# Derive post sentiment label based on sentiment score\n",
    "df_post_with_sentiment = (\n",
    "    df_post_with_sentiment\n",
    "    .withColumn(\"post_sentiment_label\",\n",
    "                F.when(df_post_with_sentiment[\"post_sentiment_score\"] > 0, \"positive\")\n",
    "                .when(df_post_with_sentiment[\"post_sentiment_score\"] < 0, \"negative\")\n",
    "                .otherwise(\"neutral\")\n",
    "               )\n",
    "    .withColumn(\"post_created_utc\", \n",
    "               F.from_unixtime(F.col(\"created_utc\")).cast(T.TimestampType())\n",
    "              )\n",
    ")\n",
    "\n",
    "# Apply UDF to create column for commentsentiment score\n",
    "df_comment_with_sentiment = df_comment.withColumn(\"comment_sentiment_score\", sentiment_score_udf(df_comment[\"body\"]))\n",
    "\n",
    "# Derive commet sentiment label based on sentiment score\n",
    "df_comment_with_sentiment = (\n",
    "    df_comment_with_sentiment\n",
    "    .withColumn(\"comment_sentiment_label\",\n",
    "                F.when(df_comment_with_sentiment[\"comment_sentiment_score\"] > 0, \"positive\")\n",
    "                .when(df_comment_with_sentiment[\"comment_sentiment_score\"] < 0, \"negative\")\n",
    "                .otherwise(\"neutral\")\n",
    "               )\n",
    "    .withColumn(\"comment_created_utc\", \n",
    "                F.from_unixtime(F.col(\"created_utc\")).cast(T.TimestampType())\n",
    "               )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f7bad8-6f8e-43ef-970c-eecbe831fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join posts and comments dataframes\n",
    "df_joined = (\n",
    "    df_post_with_sentiment\n",
    "    .join(df_comment_with_sentiment\n",
    "          , df_post_with_sentiment.id == df_comment_with_sentiment.post_id\n",
    "          , \"left_outer\"\n",
    "         )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15bd3a38-51fe-4552-9eb1-5f9f23c43db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df_joined.select(\n",
    "    df_post_with_sentiment[\"id\"].alias(\"post_id\"),\n",
    "    df_post_with_sentiment[\"title\"],\n",
    "    df_post_with_sentiment[\"score\"],\n",
    "    df_post_with_sentiment[\"num_comments\"],\n",
    "    df_post_with_sentiment[\"author\"].alias(\"post_author\"),\n",
    "    df_post_with_sentiment[\"post_created_utc\"],\n",
    "    df_post_with_sentiment[\"url\"],\n",
    "    df_post_with_sentiment[\"upvote_ratio\"],\n",
    "    df_post_with_sentiment[\"over_18\"],\n",
    "    df_post_with_sentiment[\"edited\"],\n",
    "    df_post_with_sentiment[\"spoiler\"],\n",
    "    df_post_with_sentiment[\"stickied\"],\n",
    "    df_post_with_sentiment[\"selftext\"],\n",
    "    df_post_with_sentiment[\"post_sentiment_score\"],\n",
    "    df_post_with_sentiment[\"post_sentiment_label\"],\n",
    "    df_comment_with_sentiment[\"id\"].alias(\"comment_id\"),\n",
    "    df_comment_with_sentiment[\"body\"].alias(\"comment_body\"),\n",
    "    df_comment_with_sentiment[\"author\"].alias(\"comment_author\"),\n",
    "    df_comment_with_sentiment[\"comment_created_utc\"],\n",
    "    df_comment_with_sentiment[\"score\"].alias(\"comment_score\"),\n",
    "    df_comment_with_sentiment[\"edited\"].alias(\"comment_edited\"),\n",
    "    df_comment_with_sentiment[\"stickied\"].alias(\"comment_stickied\"),\n",
    "    df_comment_with_sentiment[\"parent_id\"].alias(\"comment_parent_id\"),\n",
    "    df_comment_with_sentiment[\"num_replies\"].alias(\"comment_num_replies\"),\n",
    "    df_comment_with_sentiment[\"permalink\"],\n",
    "    df_comment_with_sentiment[\"comment_sentiment_score\"],\n",
    "    df_comment_with_sentiment[\"comment_sentiment_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b91dda00-358c-418f-9f25-0625dff6d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count checksum verification passed.\n"
     ]
    }
   ],
   "source": [
    "count_checksum_verification(df_post_with_sentiment, df_comment_with_sentiment, result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb66a7-2e16-4e9c-b6b7-17aabf626a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
